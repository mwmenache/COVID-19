{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coronavirus progression dashboard - Overview\n",
    "- Objective is to build a tool to track the progression of the Covid-19 pandemic, with up to date and reliable data\n",
    "- Data comes for the Johs Hopkins University, the source usually used in media outlets (e.g. ABC news, Le Monde...)\n",
    "\n",
    "The reaon for this dashboard to exist is that data usually available is either:\n",
    "- incomplete (e.g. limitied number of coutries, limited time period)\n",
    "- poorly presented (e.g. different  scales for diffrent coutries, lack of context)\n",
    "- not granular enough (e.g. no breakdown by state for the US or Australia)\n",
    "\n",
    "This dashboard uses all data available from Johns Hopkins and offers the following functionalities:\n",
    "- Easy to use: the output is an .html file than can be sinky opened in a web browser. No installation of any sort is required\\\n",
    "- Easy to share: the .html file can simply be sent by email\n",
    "- Free: No licence is required to ue and manipulate the dashboard\n",
    "- Easy to update with new date: Update process takes ~15s\n",
    "- Comprehensive: all time series avaiable from John Hopkins is included\n",
    "- Flexible: The user can decide what to display and  how to doplay it\n",
    "\n",
    "The dashboard is a very flexible tool and the user can play with the following:\n",
    "List of avaialble metrics: \n",
    "- Number of cumulated Confirmed cases, by day or week\n",
    "- Number of cumulated Deaths, by day or week\n",
    "- Number of Confirmed cases, by day or week\n",
    "- Number of Deaths, by day or week\n",
    "- 7-days Rolling averages of Confirmed cases, by day or week\n",
    "- 7-days Rolling averages of Deaths, by day or week\n",
    "\n",
    "Data can be displayed by Coutry, Statem, or filtered on  a selection of countries or states. For instance, it is possible to display the evolution of the total number of cases by State in the US, or by Country in Europe, or the totals worlwide.\n",
    "Data can also be filterd by date (e.g. display only the lates date to see the total number currently confirmed cases)\n",
    "\n",
    "User can also chose how to visualize the data:\n",
    "- Line chart of the 7-day rolling average of confirmed cases to see the trend of a selection of coutries\n",
    "- Bar chart of or the death rate by country \n",
    "- Many more visualizations are avaible (table, heatmaps, area charts....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pivottablejs import pivot_ui\n",
    "# Pandas options\n",
    "pd.options.display.max_rows = 999\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "# jupyter options\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions\n",
    "- string_to_date turn a string column to datetime in a Panadas DF\n",
    "- read_and_stack read the global data and stack it for furher manipulations\n",
    "- read_and_stack_US read the US data and stack it for furher manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _string_to_date(s, format):\n",
    "    \"\"\"\n",
    "    This is an extremely fast approach to datetime parsing.\n",
    "    For large data, the same dates are often repeated. Rather than\n",
    "    re-parse these, we store all unique dates, parse them, and\n",
    "    use a lookup to convert all dates.\n",
    "    \"\"\"\n",
    "    dates = {date:pd.to_datetime(date, format = format) for date in s.unique()}\n",
    "    return s.map(dates)\n",
    "\n",
    "def _read_and_stack(file):\n",
    "    \"\"\" Reads the data and format it in long format with .stack() \n",
    "    with one row by country, province and date.\n",
    "    This format is more flexible than the original format and can be\n",
    "    use to quickly build a dashboard with pivottablejs\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file: String\n",
    "        the file to import, from the COVID-19 repository on github:\n",
    "        https://github.com/CSSEGISandData/COVID-19.git\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    - df:\n",
    "        pandas Series, stacked, with 1 row per ['Province/State', 'Country/Region', 'Date', 'Week']\n",
    "    \n",
    "    See Also\n",
    "    --------\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    confirmed = _read_and_stack(\"Confirmed\")\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    df = (pd\n",
    "          .read_csv(rf\"csse_covid_19_data\\csse_covid_19_time_series\\time_series_covid19_{file}_global.csv\")\n",
    "          .reset_index()\n",
    "          .drop([\"index\", \"Lat\", \"Long\"], axis=1)\n",
    "          .set_index(['Province/State', 'Country/Region'])\n",
    "          .stack()\n",
    "          .reset_index()\n",
    "         )\n",
    "    df[\"Date\"] = _string_to_date(df[\"level_2\"], \"%m/%d/%y\")\n",
    "    df[\"Week\"] = df.Date.dt.year * 100 + df.Date.dt.week\n",
    "    df = (df\n",
    "          .set_index(['Province/State', 'Country/Region', 'Date', 'Week'])\n",
    "          .drop(\"level_2\", axis=1)\n",
    "         )\n",
    "    df.columns = [file]\n",
    "    \n",
    "    return df[file]\n",
    "\n",
    "\n",
    "def _read_and_stack_US(file):\n",
    "    \"\"\" Reads the data and format it in long format with .stack() \n",
    "    with one row by country, province, county and date.\n",
    "    This format is more flexible than the original format and can be\n",
    "    use to quickly build a dashboard with pivottablejs\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file: String\n",
    "        the file to import, from the COVID-19 repository on github:\n",
    "        https://github.com/CSSEGISandData/COVID-19.git\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    - df:\n",
    "        pandas Series, stacked, with 1 row per ['Province/State', 'Country/Region', 'Date', 'Week']\n",
    "    \n",
    "    See Also\n",
    "    --------\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    confirmed = _read_and_stack(\"Confirmed\")\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    df = (pd\n",
    "          .read_csv(rf\"csse_covid_19_data\\csse_covid_19_time_series\\time_series_covid19_{file}_US.csv\")\n",
    "          .reset_index()\n",
    "          .rename(columns={ \"Province_State\":\"Province/State\"\n",
    "                          , \"Country_Region\": \"Country/Region\"\n",
    "                          , \"Admin2\":\"County\"}\n",
    "                 )\n",
    "          .drop([  \"index\", \"Lat\", \"Long\", \"Long_\"\n",
    "                 , \"UID\", \"iso2\", \"iso3\", \"code3\"\n",
    "                 , \"FIPS\", \"Combined_Key\", \"Population\"]\n",
    "                , axis=1, errors=\"ignore\")\n",
    "          .set_index(['Province/State', 'Country/Region', 'County'])\n",
    "          .stack()\n",
    "          .reset_index()\n",
    "         )\n",
    "    df[\"Date\"] = _string_to_date(df[\"level_3\"], \"%m/%d/%y\")\n",
    "    df[\"Week\"] = df.Date.dt.year * 100 + df.Date.dt.week\n",
    "    df = (df\n",
    "          .set_index(['Province/State', 'Country/Region', \"County\", 'Date', 'Week'])\n",
    "          .drop(\"level_3\", axis=1)\n",
    "         )\n",
    "    df.columns = [file]\n",
    "    \n",
    "    return df[file]\n",
    "\n",
    "\n",
    "\n",
    "# df = _read_and_stack(\"Confirmed\")\n",
    "# # df.columns\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid-19 progression dashboard\n",
    "Per country, province and date: confirmed, death, new confirmed and new deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' When Province/State is mussing , it refers to the main bulk of \\nthe country. e.g for France, when Province/State is missing the data refers \\nto metropolitan France, as oppose to some specific Province\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\nrate = death / confirmed\\nnew_confirmed = daily count of confirmed cases\\nnew_deaths = dailty count of deaths\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Build a sigle DataFrame with count of Confirmed cases and count of Deaths \n",
    "# by country, province and date\n",
    "# 1.1 Global data\n",
    "files=[\"Confirmed\", \"Deaths\"]\n",
    "df_global = pd.DataFrame()\n",
    "for file in files:\n",
    "    df_global[file] = _read_and_stack(file)\n",
    "\n",
    "df_global = df_global.reset_index()\n",
    "\n",
    "# 1.2 US data\n",
    "# a. Read raw data - county level\n",
    "df_US = pd.DataFrame()\n",
    "for file in files:\n",
    "    df_US[file] = _read_and_stack_US(file)\n",
    "\n",
    "df_US = df_US.reset_index()\n",
    "\n",
    "# b. aggregate at State level to be consistent with the global data\n",
    "df_US = (df_US\n",
    "         .groupby(['Country/Region', 'Province/State', 'Date', 'Week'])\n",
    "         .sum()\n",
    "         .reset_index()\n",
    "        )\n",
    "\n",
    "\n",
    "# 2. Clean up the data\n",
    "# 2.1 Compile Global and US data\n",
    "df = pd.concat([  df_global[df_global[\"Country/Region\"] != \"US\"]\n",
    "                , df_US]\n",
    "                , sort=True\n",
    "              )\n",
    "df =  df[[\"Country/Region\", \"Province/State\", \"Date\", \"Week\", \"Confirmed\", \"Deaths\"]]\n",
    "\n",
    "\n",
    "# 2.2 Replace missing Province/State by the name of the country\n",
    "\"\"\" When Province/State is mussing , it refers to the main bulk of \n",
    "the country. e.g for France, when Province/State is missing the data refers \n",
    "to metropolitan France, as oppose to some specific Province\n",
    "\"\"\"\n",
    "df['Province/State'] = df['Province/State'].fillna(df['Country/Region'])\n",
    "\n",
    "# 2.3 sort by Country, Province and date\n",
    "df = (df\n",
    "      .sort_values(['Country/Region', \"Province/State\", \"Date\"])\n",
    "      .reset_index()\n",
    "      .drop(\"index\", axis=1)\n",
    "     )\n",
    "\n",
    "# 3. Add the mortality rate, number of new confirmed and number of new deaths\n",
    "\"\"\"\n",
    "rate = death / confirmed\n",
    "new_confirmed = daily count of confirmed cases\n",
    "new_deaths = dailty count of deaths\n",
    "\"\"\"\n",
    "\n",
    "# 3 Add the mortality rate, number of new confirmed and number of new deaths\n",
    "df[\"rate\"] = (df.Deaths / df.Confirmed).fillna(0)\n",
    "df[\"New Confirmed\"] = df.groupby(['Country/Region', \"Province/State\"]).Confirmed.diff().fillna(0)\n",
    "df[\"New Deaths\"] = df.groupby(['Country/Region', \"Province/State\"]).Deaths.diff().fillna(0)\n",
    "\n",
    "# 4. Add rolling averages for New cases and new deaths\n",
    "rolling = df.groupby(['Country/Region', \"Province/State\"])[\"New Confirmed\", \"New Deaths\"].rolling(7).mean()\n",
    "rolling.columns = [\"New Confirmed Rolling\", \"New Deaths Rolling\"]\n",
    "# df = df.set_index(['Country/Region', \"Province/State\"])\n",
    "df[\"New Confirmed Rolling\"] = rolling.reset_index()[\"New Confirmed Rolling\"]\n",
    "df[\"New Deaths Rolling\"] = rolling.reset_index()[\"New Deaths Rolling\"]\n",
    "\n",
    "# df.loc[df[\"Country/Region\"] == \"US\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the dashboard with pivottablejs.pivot_ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"time_series_pivotchart.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1aabeefada0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the interactive table / chart\n",
    "pivot_ui(df,outfile_path=\"time_series_pivotchart.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rescaled dashboard to compare progression per country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescale to log scale and start when the number of confirmed cases reaches 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmenache\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Get country lelbel totals\n",
    "df2 = df.groupby([\"Country/Region\", \"Date\"]).sum()\n",
    "\n",
    "df2 = df2.loc[df2.Confirmed >= 30]\n",
    "df2[\"log_Confirmed\"] = np.log(df2[\"Confirmed\"])\n",
    "df2[\"log_Deaths\"] = np.log(df2[\"Deaths\"])\n",
    "df2[\"Rate\"] = df2[\"Deaths\"] / df2[\"Confirmed\"] \n",
    "df2 = df2.replace([np.inf, -np.inf], 0)\n",
    "df2 = df2.reset_index()\n",
    "df2[\"Date_ini\"] = df2[\"Date\"]\n",
    "df2[\"Date\"] = df2.groupby([\"Country/Region\"]).cumcount()\n",
    "df2 = (df2\n",
    "       .set_index([\"Country/Region\", \"Date\", \"Date_ini\"])\n",
    "       .loc[:, [\"Confirmed\", \"log_Confirmed\", \"Deaths\", \"log_Deaths\", \"rate\"]]\n",
    "      )\n",
    "\n",
    "# Recalculate the rate\n",
    "df2[\"rate\"] = df2.Deaths / df2.Confirmed\n",
    "\n",
    "# df2.loc[[\"France\", \"China\"]]\n",
    "# df2.loc[\"Turkey\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the dashboard with pivottablejs.puivot_ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"country_comparison_rescaled.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1aabaf00390>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the interactive table / chart\n",
    "pivot_ui(df2,outfile_path=\"country_comparison_rescaled.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
